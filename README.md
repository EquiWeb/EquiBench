# EquiBench
Coding benchmark for evaluating the performance of LLMs in both unserstanding and generating code. Specifically benchmark focuses on performance of LLMs as coding agents within large codebases, and their ability to understand and generate code in a way that is consistent and compatible with the existing codebase.
---
v1 React repo; PR 32224 (this is probbably in the training set, but proves the concept and provides a starting point for future iterations)